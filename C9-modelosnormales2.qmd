# Modelos lineales

Había un montón de tipos de modelos que puede ocupar para analizar sus datos, desde lo más básico hasta ellos que pueden tomar combinaciones complicadas para representar sus datos. El prepósito de un modelo, generalmente, es crear una combinación de variables que puede representar una relación entre variables en una manera correcta y que crear valores predictivos.

Con sistemas naturales, la idea puede ser tener predicciones para el futuro, pero frecuentemente se interesa mas la pregunta si haya relaciones entre variables o no.

Es super importante tener y saber una hipótesis acá, y anota que nunca puede probar que tu hipótesis es verdad, sino que significancia decía que no hay evidencia que tu hipótesis es incorrecto. Tampoco, puede decir que una variable explicativa causa su variable de respuesta.

![](images/Correlation_Vs_Causation_-_2019-es.png){fig-align="center" width="600"}

¡Por esta razón, su interpretación de sus propios resultados con conocimiento profundo de su proyecto es super importante!

Casi nunca puede decir que algo causa otra, pero si conozca bien su proyecto y sistema, podría elucidar conclusiones e ideas desde sus correlaciones.

# ¿Como funciona los modelos lineales?

De nivel más básico, un modelo lineal toma dos variables y te cuenta la relación entre los dos, incluyendo si suben/bajan juntos y con qué incremento.  

La fórmula super básico es así:

**Y = mX + b**

X e Y son tus variables explicativas (X) y respuesta (Y)

M es la inclinación, o sea, el rato de cambio por Y con cada unidad de X

B es la intersección (o sea, cuando no hay ninguna del Y: ¿cuántas unidades del X hay?)

Entonces, desde un modelo lineal básico, puede aprender mucho. Este tipo de modelo mas básico, con una variable de respuesta y una variable explicativa es un modelo lineal, y se usa el función ‘lm()’

Por ejemplo:

```{r, include = FALSE}
library(vegan)
library(lme4)
library(tidyverse)
library(DHARMa)
library(car)
library(MASS)
library(rstatix)


data("mite")
data("mite.env")

ac <- bind_cols(mite$Brachy, mite.env)
ac <- ac %>%
  rename("AcaroBrachy" = ...1, "DensSustrato" = SubsDens, "CuentaAgua" = WatrCont, "Sustrato" = Substrate, "Arbusto" = Shrub)

```


```{r, message=FALSE, warning=FALSE}
ac %>%
  ggplot(aes(x=AcaroBrachy, y=CuentaAgua))+
  geom_point()+
  geom_smooth(method="lm")
```

```{r}
lmej <- lm(data=ac, AcaroBrachy ~ CuentaAgua)
summary(lmej)
```
Eso es un ejemplo básico, pero normalmente en ecología/agronomía, los datos y relaciones son complicados. Si haya algo en el campo, tendría mas que una variable explicativa, porque hay otras cosas que se afectan su variable respuesta. Además, hay mas etapas que hacer su gráfico y después el modelo. Los supuestos son super importantes y sus tipos de datos también. Así que, empezamos con GLM.

# Empezando con GLM

GLMs son similares a modelos lineales, pero son mas flexible, y tienen poquito más tolerancia a residuos non-normales. Entonces, puede hacer un análisis/modelo más complicado con GLM.

Para hacer un modelo, necesita una pregunta y/o una hipótesis.

Por ejemplo: acá tenemos la abundancia de Cordia bicolor, precipitación, elevación, edad del bosque, geología, y hábitat. Supongo que la pregunta central es cuales factores se impactan lo distribución de un árbol, Cordia bicolor en la isla Barro Colorado.

```{r}
head(ac)
```

La hipótesis puede incluir algunas de las variables o todos.

Una hipótesis puede ser así: Habría una abundancia más alta de Cordia bicolor con más precipitación y menos elevación. Entonces, probamos los variables de precipitación y elevación. Podemos incluir también geología, hábitat o edad del bosque, pero no son lo prioridad.

Una pregunta puede ser: ¿Cuáles factores medio ambientales impacta la abundancia del Cordia bicolor?

Así podemos usar todos los variables para ver cual tiene impacto.

* No olvide a cambiar los tipos de datos ANTES de hacer modelos (y si quiere, transformar)

```{r}

ac$DensSustrato <- as.numeric(ac$DensSustrato)
ac$CuentaAgua <- as.numeric(ac$CuentaAgua)
ac$Sustrato <- as.factor(ac$Sustrato)
ac$Arbusto <- as.factor(ac$Arbusto)
ac$Topo <- as.factor(ac$Topo)


```

* Y sacar sus outliers

```{r}
ac %>% 
  identify_outliers(AcaroBrachy)

quartiles <- quantile(ac$AcaroBrachy, probs=c(.25, .75), na.rm = FALSE)
IQR <- IQR(ac$AcaroBrachy)

# -3 deviaciónes estander 
Lower <- quartiles[1] - 1.5*IQR

# +3 deviaciónes estander
Upper <- quartiles[2] + 1.5*IQR 

acso <- subset(ac, ac$AcaroBrachy > Lower & ac$AcaroBrachy < Upper)

```

* Además debería probar por correlaciónes antes

```{r}
library(corrgram)
acc <- ac[1:3]
corrgram(acc)
```

# Opciones para evaluar

Lo mejor modelo es lo mas simple, o sea, con la cantidad menor de variables explicativas. Pero, es importante considerar todos los variables que quizás afectan su variable respuesta. Y por eso, el numero de observaciones es importante: no puede usar mas variables explicativas que observaciones, y de hecho si tiene menos de diez observaciones debería usar menos variables explicativas que la mitad de sus observaciones.

# familia y supuestos

Es super importante usar una familia que tiene sentido por sus datos. Además, algunas familias son poquito mas tolerante a datos con mas varianza o nonnormalidad (pero todavía necesita probar estas supuestos)

Puede elegir su familia antes de hacer algo (de hecho, debe saber cual piensa que te sirve antes), pero igual puede probarlas con los supuestos.

### Sintaxis completo para un glm

glm(data=data, var_res \~ var_exp1 + var_exp2 + var_exp3 \* var_exp4, family="poisson")

### 1. Emepzar con una familia (si no elije una, es Gaussian)

```{r}
# acá es gaussian
ABBase <- glm(data=ac, AcaroBrachy ~ DensSustrato + CuentaAgua + Sustrato + Topo)

simResABBase <-simulateResiduals(ABBase) #DHARMa: hace resiudos y graficos para evaluar normalidad y homogeneidad de varianza
# si hay líneas super curvados, rojo o valor P<0.05) en el QQ plot (izquierda) no vale

plot(simResABBase)
# entonces acá es malo

```

```{r}
# intenta de nuevo con distinta familia (binomio negativo)
ABBaseBN <- glm.nb(data=ac, AcaroBrachy ~ DensSustrato + CuentaAgua + Sustrato + Topo)

simResABBaseBN <-simulateResiduals(ABBaseBN) #DHARMa: hace resiudos y graficos para evaluar normalidad y homogeneidad de varianza
# si hay líneas super curvados, rojo o valor P<0.05) en el QQ plot (izquierda) no vale

plot(simResABBaseBN)
# mejor, pero todavia con problemas

```

```{r}
# intenta de nuevo con distinta familia (binomio negativo)
ABBasep <- glm(data=ac, AcaroBrachy ~ DensSustrato + CuentaAgua + Sustrato + Topo, family="poisson")

simResABBasep <-simulateResiduals(ABBasep) #DHARMa: hace resiudos y graficos para evaluar normalidad y homogeneidad de varianza
# si hay líneas super curvados, rojo o valor P<0.05) en el QQ plot (izquierda) no vale

plot(simResABBasep)
# superrr mal
```

Ninguno de estos tres modelos se cumple con los supuestos. Pero, puede elegir lo que es mejor ahora, porque a veces cuando eliminar variables, resultara que uno u otro fue el problema. Hice esto con los valores del criterio de información de Akaike (CIA o AIC).

```{r}
library(MuMIn)
lr_output.AIC <- model.sel(ABBase, ABBaseBN, ABBasep) # incluir los modelos de interés

lr_AIC.table<-as.data.frame(lr_output.AIC)[7:12] # estas columnas pueden cambiar, entonces puede ver en el tab 'environment' también

lr_AIC.table
```

Acá la mejor familia es el binomio negativo, que también fue lo mas cerca a normal según los gráficos. Entonces parte allá. Antes que sigue, tenemos que probar el intercorrelación también con 'VIF' del paquete 'car'.

```{r}
vif(ABBaseBN) 
# todos los valores deben ser <2
```

No hay intercorrelación problemática, entonces siga.

# Elegiendo modelo mejor

Había ambas opciones para elegir un modelo, y eliminar variables que son menos importante. Acá muestra tres básicos:

### 1. Eliminación hacia atrás con Drop1/AIC

Con regresión eliminación hacia atrás, empezamos con todas las variables y eliminarlas uno a uno hasta que queda uno y después elige lo mejor modelo con AIC. Esto es bueno porque puede elegir una a una las variables que son más o menos efectivo. Es malo si tiene algunas variables si son obligatorias dejar.

1.  Empieza con un modelo con todas sus variables explicativas. Elegir una familia adecuada y probar por correlación/normalidad/homogeneidad de varianza.
2.  Usar ‘drop1’ con prueba preferida (‘chisq’ es mi favorito) para identificar la variable con lo menor impacto
3.  Hacer un nuevo modelo con este variable eliminado
4.  Rehacerlo hasta que queda uno o que todos son significantes

```{r}
# parte con 'ABBaseBN' del los modelos que ya he hecho
drop1(ABBaseBN, test="Chisq")
# lo menos fuerte es DensSustrato (número más grande)
```

```{r}
ABBaseBN2 <- glm.nb(data=ac, AcaroBrachy ~ CuentaAgua + Sustrato + Topo)

simResABBaseBN2 <-simulateResiduals(ABBaseBN2) #DHARMa: hace resiudos y graficos para evaluar normalidad y homogeneidad de varianza
# si hay líneas super curvados, rojo o valor P<0.05) en el QQ plot (izquierda) no vale

plot(simResABBaseBN2)
# todavia no cumple con los supuestos
```

De nuevo

```{r}
drop1(ABBaseBN2, test="Chisq")
# cuenta agua
```

```{r}
ABBaseBN3 <- glm.nb(data=ac, AcaroBrachy ~ Sustrato + Topo)

simResABBaseBN3 <-simulateResiduals(ABBaseBN3) 

plot(simResABBaseBN3)
# excelente! Ahora se cumple con los supuestos
```

De nuevo

```{r}
drop1(ABBaseBN3, test="Chisq")
# todo tiene significancia, entonces podemos parar
```

Así que ahora todo es significante, es la hora de probar todos los modelos con AIC.

```{r}
library(MuMIn)
lr_output.AIC <- model.sel(ABBase, ABBaseBN, ABBasep, ABBaseBN2, ABBaseBN3) # incluir los modelos de interés

lr_AIC.table<-as.data.frame(lr_output.AIC)[7:12] # estas columnas pueden cambiar, entonces puede ver en el tab 'environment' también

lr_AIC.table
```

ABBaseBN3, o sea el último, es lo mejor modelo.

```{r}
# probar supuestos 
simResABBaseBN3 <-simulateResiduals(ABBaseBN3) 

plot(simResABBaseBN3)

vif(ABBaseBN3)

plot(ABBaseBN3)


```

Así que el modelo se cumple con todos los supuestos, ve los resultados.

```{r}
# resultados
summary(ABBaseBN3)
```

Así que los dos variables que quedan son factores, en los resultados, se muestra todos los niveles y su significancia. Que puede decir desde los resultados?

La primera colúmna (Estimate) es la inclinación del modelo. O sea que comparado al intercept, el sustrato Sphagn2 tiene 0.5x la abundancia del intercept. Es imporante ver y tener en cuenta la inclinación porque puede tener un modelo que tiene muchísimas variables significantes, pero la diferencia es super poco (por ejemplo solo gana un más abeja). En el 'estimate' un valor positivo es más grande, y negativo es más chico.

'Std. error' o sea, error estander, es el error. Siempre hay duda en modelos, pero un modelo super bien tiene un nivel bajo de duda, o sea, un error estander más chico.

El Z-value (o t-value) es importante porque puede evaluar la fuerza del estimación por variable. O sea, su Z/T es su estimate dividio por el error. Entonces, un valor más chico tiene un error más grande, y tiene más duda.

El Pr es su valor p. Usa eso para evaluar significancia. Había un superenfoque en significancia en ecologia, pero debería leer bien todo, porque es super posible que tiene un modelo significante pero debíl. Las estrellas significa cuales variables son significadamente distinto al resto (o sea, que tiene una abundancia significiativamente alto o bajo comparado al resto).

Vamos a hablar de más indicaciones del fuerza de su modelo más adelante.

### 2. regresión 'forward'

Usa regresión forward para añadir de forma rapido las variables más impactantes.

Empece con un modelo vacio (o sea var.res \~ 1), sin variables explicativas y un modelo con todas las variables de interés.

Usa el función 'step' para elegir la proxima variable que debería añadir hasta que nada son significados en step.

Puede probar/elegir su modelo mejor con AIC y no olvide a probar los supuestos.

```{r}
ModVac <- glm(data=ac, AcaroBrachy ~ 1) # modelo con ninguna variable explicativa
ModTodo <- glm(data=ac, AcaroBrachy ~ DensSustrato + CuentaAgua + Sustrato + Topo ) # modelo con todas las variables explicativas

# nombre       step(partida, scope=list(lower=vacio, upper=todo))
Mod_forward <- step(ModVac, scope=list(lower=ModVac, upper=ModTodo))

```

Acá tiene dos respuestas a la pregunta, cuales variables son mejores por el modelo. Usa AIC para decidir, y puede ver que el modelo mejor con un variable es Cuenta Agua y no se da un modelo con 2 variables porque no sea mejor.

Pero, si ya no he probado sus supuestos, esto puede ser equivocado. Por ejemplo, los modelos acá están hechos con la familia gaussian, que es malo. Si hace de nuevo con binomio negativo, cambiaría los datos.

```{r}
ModVac <- glm.nb(data=ac, AcaroBrachy ~ 1)
ModTodo <- glm.nb(data=ac, AcaroBrachy ~ DensSustrato + CuentaAgua + Sustrato + Topo )

Mod_forward <- step(ModVac, scope=list(lower=ModVac, upper=ModTodo))

```

Así que ahora ocupa la familia adecuada, había más opciones. Había modelos hasta tres variables explicativas y lo mejor AIC es lo con tres.

Probamos esta variable:

```{r}
RF3 <- glm.nb(data=ac, AcaroBrachy ~ CuentaAgua + Topo + Sustrato)

simResRF3 <-simulateResiduals(RF3) 

plot(simResRF3)

vif(RF3)
# podemos ver que no es exactamente bien

summary(RF3)
# pero se sale similar que el topo hummock es super significante y con el error más chico
```

Siempre, siempre probar sus modelos después de elegirlas, porque sus resultados no son validos si no cumpla con los supuestos.

### 3. regresión 'backward'

Regresión hacia atrás, o sea, backward, es lo mismo idea que 'forward' pero empezamos con un modelo lleno y eliminar variables en vez de añadir. La distinción entre eso y la versión 'stepwise' es que acá hice todo el mismo tiempo. Puede ser bueno, pero también hay más posibilidad de error porque no prueba los supuestos en cada etapa.

```{r}
ModVac <- glm.nb(data=ac, AcaroBrachy ~ 1)
ModTodo <- glm.nb(data=ac, AcaroBrachy ~ DensSustrato + CuentaAgua + Sustrato + Topo )
# acá empieza con el modelo lleno, porque va a eliminar no añadir
Mod_forward <- step(ModTodo, scope=list(lower=ModVac, upper=ModTodo), direction='backward')
```

```{r}
RB3 <- glm.nb(data=ac, AcaroBrachy ~ CuentaAgua + Sustrato + Topo)

RB3 <- glm.nb(data=ac, AcaroBrachy ~ CuentaAgua + Topo + Sustrato)

simResRB3 <-simulateResiduals(RB3) 

plot(simResRB3)

vif(RB3)
# podemos ver que no es exactamente bien

summary(RB3)

plot(RB3)
```

Acá se sale lo mismo como regresión 'forward' pero distinto a 'stepwise backward'. Depende en su cantidad de variables, puede salir de cualquier manera.

# recursos adicionales

[Video de interpretar modelos- English](https://www.youtube.com/watch?v=boPyjojYHUY)

[Tipos de elección- Español](https://www.youtube.com/watch?v=tCXc2zl3dew)
